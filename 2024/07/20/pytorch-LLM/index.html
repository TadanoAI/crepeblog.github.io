<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>学习从零开始用Python搭建LLM | 奶油可丽饼🍭</title><meta name="author" content="奶油可丽饼🍭"><meta name="copyright" content="奶油可丽饼🍭"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言：参考视频： bilibili搬运: 【中英软字幕《从零开始用Python搭建LLM|Create a LLM from Scratch with Python – Tutorial》】 https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1vp421o7Ys&#x2F;?share_source&#x3D;copy_web&amp;vd_source&#x3D;b00375b8765cc533f81ef03">
<meta property="og:type" content="article">
<meta property="og:title" content="学习从零开始用Python搭建LLM">
<meta property="og:url" content="https://blog.creamcrepe.icu/2024/07/20/pytorch-LLM/index.html">
<meta property="og:site_name" content="奶油可丽饼🍭">
<meta property="og:description" content="前言：参考视频： bilibili搬运: 【中英软字幕《从零开始用Python搭建LLM|Create a LLM from Scratch with Python – Tutorial》】 https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1vp421o7Ys&#x2F;?share_source&#x3D;copy_web&amp;vd_source&#x3D;b00375b8765cc533f81ef03">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/06/27/aYAs14kdBTVrGhQ.png">
<meta property="article:published_time" content="2024-07-20T15:52:36.000Z">
<meta property="article:modified_time" content="2024-08-09T08:33:22.376Z">
<meta property="article:author" content="奶油可丽饼🍭">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/06/27/aYAs14kdBTVrGhQ.png"><link rel="shortcut icon" href="/img/%E5%9B%BE%E6%A0%87.png"><link rel="canonical" href="https://blog.creamcrepe.icu/2024/07/20/pytorch-LLM/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":5},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: ture,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '学习从零开始用Python搭建LLM',
  isPost: true,
  isHome: false,
  isHighlightShrink: ture,
  isToc: true,
  postUpdate: '2024-08-09 16:33:22'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (ture) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2024/06/26/zjr3sIaPb9TQJC8.jpg" onerror="onerror=null;src='https://s2.loli.net/2024/06/27/ogFMRzISiKtZVal.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/NAS/"><i class="fa-fw fas fa-floppy-disk"></i><span> NAS</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2024/06/27/aYAs14kdBTVrGhQ.png')"><nav id="nav"><span id="blog-info"><a href="/" title="奶油可丽饼🍭"><span class="site-name">奶油可丽饼🍭</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/NAS/"><i class="fa-fw fas fa-floppy-disk"></i><span> NAS</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">学习从零开始用Python搭建LLM</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-20T15:52:36.000Z" title="发表于 2024-07-20 23:52:36">2024-07-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-09T08:33:22.376Z" title="更新于 2024-08-09 16:33:22">2024-08-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="学习从零开始用Python搭建LLM"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>参考视频：</p>
<h2 id="bilibili搬运"><a href="#bilibili搬运" class="headerlink" title="bilibili搬运:"></a>bilibili搬运:</h2><blockquote>
<p>【中英软字幕《从零开始用Python搭建LLM|Create a LLM from Scratch with Python – Tutorial》】 <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vp421o7Ys/?share_source=copy_web&vd_source=b00375b8765cc533f81ef034ac277281">https://www.bilibili.com/video/BV1vp421o7Ys/?share_source=copy_web&amp;vd_source=b00375b8765cc533f81ef034ac277281</a></p>
</blockquote>
<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=1850408547&bvid=BV1vp421o7Ys&cid=1595299013&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<p>内容：</p>
<h2 id="youtube"><a href="#youtube" class="headerlink" title="youtube:"></a>youtube:</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://youtu.be/UU1WVnMk4E8?si=Ev66IcmcSJFPElgZ">https://youtu.be/UU1WVnMk4E8?si=Ev66IcmcSJFPElgZ</a></p>
</blockquote>
<blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/UU1WVnMk4E8?si=eMyC3El49BVKR4V7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</blockquote>
<h1 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h1><p>本文依照搬运YouTube视频对大语言模型<strong>Large Language Models【后续简称为LLM】</strong>背后的数据处理，数学和Transformer进行解析，帮助个人深刻理解LLMs的工作原理以及他们的各种应用</p>
<h5 id="训练目标为二元语言模型"><a href="#训练目标为二元语言模型" class="headerlink" title="训练目标为二元语言模型"></a>训练目标为二元语言模型</h5><h1 id="安装环境："><a href="#安装环境：" class="headerlink" title="安装环境："></a>安装环境：</h1><p><strong>相关推荐：</strong></p>
<figure class="gallery-group">
  <img class="gallery-group-img no-lightbox" src='https://s2.loli.net/2024/06/27/fmDXNEvLjBu7ngq.png' alt="Group Image Gallery">
  <figcaption>
  <div class="gallery-group-name">anaconda配置与基础指令</div>
  <p>学会使用anaconda</p>
  <a href='https://blog.creamcrepe.icu/2024/07/04/pytorch-anaconda/'></a>
  </figcaption>
  </figure>
  

<figure class="gallery-group">
  <img class="gallery-group-img no-lightbox" src='https://s2.loli.net/2024/06/27/fmDXNEvLjBu7ngq.png' alt="Group Image Gallery">
  <figcaption>
  <div class="gallery-group-name">pytoch环境下载与安装</div>
  <p>安装机器学习环境</p>
  <a href='https://blog.creamcrepe.icu/2024/06/26/pytorch-setting/'></a>
  </figcaption>
  </figure>
  

<p>为了使内容清晰，将会使用 <strong>Jupyter Notebooks</strong> ，在使用浏览器编写之前要先通过<code>anaconda</code>配置好环境，配置的教程可以参考以上相关推荐</p>
<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><p>前文中<code>env</code>配置也有不一样的教学，该处方式也是创建新的虚拟环境，不一样的虚拟环境不会让库交叉产生不可挽回的问题</p>
<p>在<code>anaconda</code>中，先搭建一个适合开发的环境,每个人可以设置不一样路径</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入f盘符</span></span><br><span class="line">f:</span><br><span class="line"><span class="comment">#cd文件夹</span></span><br><span class="line"><span class="built_in">cd</span> Programs</span><br><span class="line"><span class="comment">#cd LLM</span></span><br><span class="line"><span class="built_in">cd</span> LLM</span><br><span class="line"><span class="comment">#make dir设置环境</span></span><br><span class="line">mkdir large<span class="literal">-language-models</span></span><br><span class="line"><span class="comment">#创建环境</span></span><br><span class="line">python <span class="literal">-m</span> venv cuda</span><br><span class="line"><span class="comment">#激活</span></span><br><span class="line">activate</span><br></pre></td></tr></table></figure>

<p>现在我们有了一个名为<code>cuda</code>的环境</p>
<p>我们要为其安装库：</p>
<table>
<thead>
<tr>
<th align="center">库名</th>
<th align="center">介绍</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>matpotlib</code></td>
<td align="center">用于在 Python 中创建静态、交互式和动画可视化的广泛使用的库。它提供了类似于 MATLAB 的绘图界面，能够生成各种类型的图形。</td>
</tr>
<tr>
<td align="center"><code>numpy</code></td>
<td align="center">用于科学计算的核心库之一。它提供了高性能的多维数组对象以及用于操作这些数组的多种工具。NumPy 通常用于数值计算、线性代数、统计分析等领域。</td>
</tr>
<tr>
<td align="center"><code>pylmza</code></td>
<td align="center">用于实现 Lempel-Ziv-Markov 链算法（LZMA）的 Python 库。LZMA 是一种无损数据压缩算法，以其高压缩率和相对快速的压缩和解压缩速度而闻名。Pylmza 库可以用于压缩和解压缩数据流，通常用于文件压缩和归档。【他应该是引用c++的】</td>
</tr>
<tr>
<td align="center"><code>ipykernel</code></td>
<td align="center"><code>Jupyter Notebook</code>和其他 <code>Jupyter</code> 环境中的一个关键组件，它是一个<code>Jupyter</code>内核（Kernel）实现，允许 Jupyter Notebook 与 Python 代码进行交互。</td>
</tr>
<tr>
<td align="center"><code>jupyter</code></td>
<td align="center">用于创建和共享包含代码、公式、可视化和文本的文档。<code>Jupyter</code> 的核心组件是<code> Jupyter Notebook</code>，它为数据科学、科学计算和机器学习提供了一个交互式环境。Jupyter 支持多种编程语言（通过内核），其中最常用的是<code> Python</code>。</td>
</tr>
</tbody></table>
<p>我们大概需要安装这五类库的环境</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install matpotlib numpy pylmza ipykernel jupyter</span><br></pre></td></tr></table></figure>

<h3 id="Jupyter-Notebook"><a href="#Jupyter-Notebook" class="headerlink" title="Jupyter Notebook"></a>Jupyter Notebook</h3><p>安装完成环境后，我们进入Jupyter Notebook</p>
<p>如果是按上面代码建立的环境，那么jupyter一般不会路径错误</p>
<p>如果是自己另外搭建的环境，需要引导jupyter</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#引导Jupyter Notebook打开路径</span></span><br><span class="line">F:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> Programs\LLM</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动Jupyter Notebook</span></span><br><span class="line">Jupyter Notebook</span><br></pre></td></tr></table></figure>

<p>用<code>jupyter</code>创建一个<code>.ipynb</code>文件，这种是notebook的ipy文件格式，打开<code>vscode</code>在相应文件夹应该就可以看见</p>
<p>在<code>jupyter</code>中打开<code>.ipynb</code>，在工具栏中<strong>Kernel-Change Kernel…-Start Preferred Kernel</strong>,选择先前构建好的名为<code>LLM</code>的环境，如果找不到需要我们在<code>anaconda</code>中退出<code>jupyter notebook</code>,把我们的环境弄上去</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python <span class="literal">-m</span> ipykernel install <span class="literal">--user</span> <span class="literal">--name</span>=LLM <span class="literal">--display-name</span> <span class="string">&quot;LLM-CUDA&quot;</span></span><br></pre></td></tr></table></figure>

<p>重新进入<code>jupyter notebook</code>，<strong>Kernel-Change Kernel…-Start Preferred Kernel</strong>选择LLM-CUDA</p>
<p>尝试写内容测试配置是否完成</p>
<h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><p>可以使用电子书，之类的东西进行文本构建，以范文为例</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.gutenberg.org/">免费电子书 |古腾堡项目 (gutenberg.org)</a></p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/sakuraumi/Sakura-13B-Galgame/discussions/1">樱海&#x2F;Sakura-13B-加尔盖姆 ·提供一些数据 (huggingface.co)</a></p>
</blockquote>
<blockquote>
<p>@article{chen2022cped,<br>    title&#x3D;(CPED): A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI,<br>    author&#x3D;Yirong Chen and Weiquan Fan and Xiaofen Xing and Jianxin Pang and Minlie Huang and Wenjing Han and Qianfeng Tie and Xiangmin Xu,<br>    journal&#x3D;arXiv preprint arXiv:2205.14727,<br>    year&#x3D;2022,<br>    url&#x3D;<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.14727">https://arxiv.org/abs/2205.14727</a></p>
</blockquote>
<p>我们在gutenberg.org下载一篇绿野仙踪的文章<strong>wizard of oz</strong>作为训练集</p>
<p>下载完后，删去头尾那些没用的东西，留下文章，以免没用的东西干扰我们的预测结果</p>
<p>这样子我们就获得了一份可以用于训练的数据集，我们至少在这个文本上训练一个transformer或后台语言模型</p>
<h1 id="训练："><a href="#训练：" class="headerlink" title="训练："></a>训练：</h1><h3 id="建立字典对字符进行编码"><a href="#建立字典对字符进行编码" class="headerlink" title="建立字典对字符进行编码"></a>建立字典对字符进行编码</h3><p>在<code>jupyter notebook</code>上打开文本,只读，<code>utf-8</code>编码</p>
<p>只读赋值为<code>text</code>函数，打印总字数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(text))</span><br></pre></td></tr></table></figure>



<p>put:<strong>232309</strong></p>
<p>或者我们可以直接打印现实前200个字母</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"><span class="built_in">print</span>(text[:<span class="number">200</span>])</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2024/07/31/WJTjrSQfodxpV3X.png" alt="image-20240731191525425"></p>
<p>现在我们需要设置一个名字为chars的变量作为所有字排序的文本集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line">chars = <span class="built_in">sorted</span>(<span class="built_in">set</span>(text))</span><br><span class="line"><span class="built_in">print</span>(chars)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(chars))</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2024/07/31/h9V8IE4H1rbxd6s.png" alt="image-20240731221947304"></p>
<p>用<strong>vocabulary_size</strong>来作为总长标记</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line">chars = <span class="built_in">sorted</span>(<span class="built_in">set</span>(text))</span><br><span class="line"><span class="built_in">print</span>(chars)</span><br><span class="line">vocabulary_size = <span class="built_in">len</span>(chars)</span><br></pre></td></tr></table></figure>





<p>创建一个字典    <strong>将字符串转换成整数</strong></p>
<p>另一个字典	<strong>将整数转换成字符串</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string_to_int = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br><span class="line">int_to_string = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center">名</th>
<th align="left">介绍</th>
<th align="left">基本语法</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>enumerate</code></td>
<td align="left">内置函数，它为可迭代对象（如列表、元组或字符串）添加一个索引计数器，并返回一个 <code>enumerate</code> 对象。这个对象可以被直接用于 <code>for</code> 循环中，以便同时获取索引和值。这在需要迭代一个集合并同时需要索引信息时非常有用。</td>
<td align="left">enumerate(iterable【迭代对象】, start&#x3D;0【索引计数的起始值】)</td>
</tr>
<tr>
<td align="center"><code>ch：i</code></td>
<td align="left">为每个<code>ch</code>【chars】添加<code>i</code>【int】</td>
<td align="left"></td>
</tr>
<tr>
<td align="center"><code>in</code></td>
<td align="left">包含于</td>
<td align="left"></td>
</tr>
<tr>
<td align="center"><code>for</code></td>
<td align="left">遍历列表，根据<code>i</code>从前往后遍历</td>
<td align="left"></td>
</tr>
<tr>
<td align="center"><code>string_to_int</code></td>
<td align="left">字典名字</td>
<td align="left"></td>
</tr>
</tbody></table>
<p>有了字典后，便可以开始编码了!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">encode = <span class="keyword">lambda</span> s: [string_to_int[c] <span class="keyword">for</span> c <span class="keyword">in</span> s]</span><br><span class="line">decode = <span class="keyword">lambda</span> l: <span class="string">&#x27;&#x27;</span>.join([int_to_string[i] <span class="keyword">for</span> i <span class="keyword">in</span> l])</span><br><span class="line"></span><br><span class="line">encoded_hello = encoded(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">decoded_hello = decoded(encoded_hello)</span><br><span class="line"><span class="built_in">print</span>(decode_hello)</span><br><span class="line"><span class="built_in">print</span>(encode_hello)</span><br></pre></td></tr></table></figure>



<p>比如说我们对hello进行编码</p>
<p><strong>encode</strong>编码：建一个<code>lambda</code>函数<code>s</code>【其实就是一个单词】来实现字符串编码的功能，<code>c</code>为【单词中的字母】遍历字符串 <code>s</code> 中的每个字符 <code>c</code></p>
<p>**decode解码:建一个<code>lambda</code>函数<code>l</code>【其实就是一串字符】来实现字符串解码的功能，<code>i</code>【每个字母的编号】为遍历编码<code>l</code>中每个数码<code>i</code></p>
<p>put:	<strong>hello [61, 58, 65, 65, 68]</strong></p>
<table>
<thead>
<tr>
<th>名</th>
<th>介绍</th>
<th>基本语法</th>
</tr>
</thead>
<tbody><tr>
<td><code>lambda</code></td>
<td>提供了一种简洁的方式来创建短小的函数，尤其在需要将函数作为参数传递时非常有用</td>
<td>lambda 参数列表: 表达式[【例】add &#x3D; lambda x, y: x + y]</td>
</tr>
<tr>
<td><code>sorted</code></td>
<td>用于对可迭代对象进行排序</td>
<td></td>
</tr>
</tbody></table>
<h5 id="规则模型"><a href="#规则模型" class="headerlink" title="规则模型"></a>规则模型</h5><p>现在我们整理一下上述代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入训练集</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">  text = f.read()</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练集排序</span></span><br><span class="line">chars = <span class="built_in">sorted</span>(<span class="built_in">set</span>(text))</span><br><span class="line"><span class="built_in">print</span>(chars)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算出现文字的长度</span></span><br><span class="line">vocabulary_size = <span class="built_in">len</span>(chars)</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立字典</span></span><br><span class="line">string_to_int = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br><span class="line">int_to_string = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#制作编码器</span></span><br><span class="line">encoded = <span class="keyword">lambda</span> s: [string_to_int[c] <span class="keyword">for</span> c <span class="keyword">in</span> s]</span><br><span class="line">decode = <span class="keyword">lambda</span> l: <span class="string">&#x27;&#x27;</span>.join([int_to_string[i] <span class="keyword">for</span> i <span class="keyword">in</span> l])</span><br></pre></td></tr></table></figure>



<h3 id="使用tourch库"><a href="#使用tourch库" class="headerlink" title="使用tourch库"></a>使用tourch库</h3><p>编码可以看出仅仅只是一个单词就需要很长的码条，训练过程中我们需要处理大量的数据，</p>
<p><strong>高效处理数据</strong>是非常重要的，所以我们将使用一个名为<code>Pytorch</code>的框架</p>
<p>让torch为我们处理数学中<strong>微积分</strong>的工作，名为<strong>张量</strong>[tensor]的<strong>数据结构</strong>和<strong>大量线性代数</strong>工作</p>
<p>在第一行中插入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>

<p>接下来我们要创建我们数据集的数据元素，将这个数据作为torch,的tensor， </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = torch.tensor(encode(text),dtype=torch.long)</span><br></pre></td></tr></table></figure>



<p>这样子就意味着我们将会拥有一个超长的整数序列</p>
<p>需要高精度计算时，选择合适的 <code>dtype</code> 可以提高程序的性能和节省内存。</p>
<p>在创建或转换张量时，可以使用 <code>torch.long</code> 指定张量的数据类型。</p>
<table>
<thead>
<tr>
<th>名</th>
<th>介绍</th>
<th>基本语法</th>
</tr>
</thead>
<tbody><tr>
<td><code>dtype</code></td>
<td>用于定义 NumPy 数组中元素的数据类型（data type）。在使用 NumPy 时，你可以通过设置 <code>dtype</code> 参数来指定数组中元素的类型。</td>
<td>dtype&#x3D;str</td>
</tr>
<tr>
<td><code> torch.long</code></td>
<td>PyTorch 中的一个数据类型指令，用于指定张量的元素类型为 64 位整数（即 <code>int64</code>）。在 PyTorch 中，数据类型（或数据类型指令）用于定义张量中存储的数据的类型，这可以影响计算的精度和效率。</td>
<td></td>
</tr>
<tr>
<td><code>torch.tensor</code></td>
<td><code>torch.tensor</code> 是 PyTorch 中用于创建张量的函数。张量（tensor）是 PyTorch 中的核心数据结构，用于存储和操作多维数组。张量类似于 NumPy 的数组，但它们可以在 GPU 上运行以加速计算。</td>
<td>long_tensor &#x3D; torch.tensor([1, 2, 3], dtype&#x3D;torch.long)</td>
</tr>
</tbody></table>
<p><img src="https://s2.loli.net/2024/08/01/TKIavg8lSjp1BGC.png" alt="image-20240801224503653"></p>
<p>data这句代码意思是，tourch库中创建tensor,数据集是对text文本进行encode的步骤，data type是torch.long，也就是张量的元素类型为 64 位整数</p>
<p>PyTorch 中常用的数据类型包括：</p>
<ul>
<li><code>torch.float32</code> 或 <code>torch.float</code>：32 位浮点数（默认浮点类型）</li>
<li><code>torch.float64</code> 或 <code>torch.double</code>：64 位浮点数</li>
<li><code>torch.int32</code> 或 <code>torch.int</code>：32 位整数</li>
<li><code>torch.int64</code> 或 <code>torch.long</code>：64 位整数</li>
<li><code>torch.int16</code>：16 位整数</li>
<li><code>torch.int8</code>：8 位整数</li>
<li><code>torch.uint8</code>：无符号 8 位整数</li>
<li><code>torch.bool</code>：布尔类型</li>
</ul>
<p>pytorch主要围绕张量展开修改，通过改变维度，相乘，进行点积</p>
<h3 id="验证和训练拆分"><a href="#验证和训练拆分" class="headerlink" title="验证和训练拆分"></a>验证和训练拆分</h3><h5 id="拆分"><a href="#拆分" class="headerlink" title="拆分"></a>拆分</h5><p>这篇文章长度非常长，</p>
<p>我们将文档的80%设定为训练集 <strong>【train_data】</strong>，剩下20%作为验证集 *<em>【val_data】*</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(data))</span><br><span class="line">train_data = data[:n]</span><br><span class="line">val_data = data[n:]</span><br></pre></td></tr></table></figure>

<p><strong>n为从前往后的总长度字数*0.8</strong></p>
<p>设置好训练集，就该设置训练</p>
<h5 id="训练原理"><a href="#训练原理" class="headerlink" title="训练原理"></a>训练原理</h5><p><img src="https://s2.loli.net/2024/08/01/lwIayEtzpZcm9LK.png" alt="image-20240801230715618"></p>
<p>训练原理如图，如果我们想要让他说出<code>hello</code>,就要设置好每个词后的引导</p>
<p><code>h</code>是我们应该给他的，让他逐步想出下一个词</p>
<p>通过前一个字母，他只会想下一个字母，这就是为什么他叫二元模型</p>
<p>张量块，其实就是把一个个单词分成不一样的批次</p>
<p>​	比如说	<strong>（[0],[1],[2],[3],[4]）</strong></p>
<p>接下来根据上下文，**[0]**变成了上文，整个块往后移动	<strong>[0]（[1],[2],[3],[4],[5]）</strong></p>
<p>没有块，就不能期望快速训练良好的性能</p>
<p>那么我们的代码可以变成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设定块的长度</span></span><br><span class="line">block_size = <span class="number">8</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#x是整个块		y是块后移一位</span></span><br><span class="line">x = train_data[:block_size]</span><br><span class="line">y = train_data[<span class="number">1</span>:block_size+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#让t跟随块循环	</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(block_size):</span><br><span class="line">    </span><br><span class="line">  context = x[:t+<span class="number">1</span>]</span><br><span class="line">  target = y[t]</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">#当输入的上下文是***	则目标是***</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;when input is&#x27;</span>, context,<span class="string">&#x27;target is&#x27;</span>, target)</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2024/08/01/eW7vNd6pj1oS8T4.png" alt="image-20240801232752700"></p>
<p>这段代码我们做了建议的目标引导语句</p>
<blockquote>
<p>设定块尺寸 &#x3D; 8</p>
<p>x 方向 &#x3D; 训练集 [从0到定块尺寸]   的单词</p>
<p>y 方向 &#x3D; 训练集 [从1到定块尺寸+1]  的单词</p>
<p>循环   [块尺寸]   次</p>
<p>上下文 &#x3D; x方向【从 0 到 第t+1次】，比如说第一次循环t&#x3D;0,就输出1个，第二次t&#x3D;1就输出2个</p>
<p>目标  &#x3D; y方向【t】</p>
</blockquote>
<p>那我们知道了怎么获取批次，那么我们来加速这些批次，在代码段第一行加上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(device)</span><br></pre></td></tr></table></figure>

<p>在cuda启用的时候采用<code>cuda</code>，否则为<code>cpu</code></p>
<p>并且把	<strong>块尺寸设定	移动到最前面</strong>，然后	<strong>设置批量处理大小</strong>	，即我们同时处理多少的块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">block_size = <span class="number">8</span> </span><br><span class="line">batch_size = <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>这是我们训练很重要的两个参数</p>
<p>当我们扩大数据规模或者使用更加复杂的机制来训练学习，就能体现他的用处</p>
<h5 id="规整模型"><a href="#规整模型" class="headerlink" title="规整模型"></a>规整模型</h5><p>现在让我们规整一下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入库和设定训练设备</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置块大小和批量处理数量</span></span><br><span class="line">block_size = <span class="number">8</span> </span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导入训练集</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;wizard_of_oz.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#训练集排序与计数</span></span><br><span class="line">chars = <span class="built_in">sorted</span>(<span class="built_in">set</span>(text))</span><br><span class="line"><span class="built_in">print</span>(chars)</span><br><span class="line">vocabulary_size = <span class="built_in">len</span>(chars)</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立字典</span></span><br><span class="line">string_to_int = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br><span class="line">int_to_string = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#制作编码器</span></span><br><span class="line">encoded = <span class="keyword">lambda</span> s: [string_to_int[c] <span class="keyword">for</span> c <span class="keyword">in</span> s]</span><br><span class="line">decode = <span class="keyword">lambda</span> l: <span class="string">&#x27;&#x27;</span>.join([int_to_string[i] <span class="keyword">for</span> i <span class="keyword">in</span> l])</span><br><span class="line"></span><br><span class="line"><span class="comment">#80%作为训练集	20%作为验证集</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(data))</span><br><span class="line">train_data = data[:n]</span><br><span class="line">val_data = data[n:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#x为块位置，y为块后移一个位置</span></span><br><span class="line">x = train_data[:block_size]</span><br><span class="line">y = train_data[<span class="number">1</span>:block_size+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#块内循环，x作为上下文，y作为目标</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(block_size):</span><br><span class="line">    context = x[:t+<span class="number">1</span>]</span><br><span class="line">    target = y[t]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#导出训练效果    </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;when input is&#x27;</span>, context,<span class="string">&#x27;target is&#x27;</span>, target)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="使用说明："><a href="#使用说明：" class="headerlink" title="使用说明："></a>使用说明：</h1><h3 id="Pytorch的使用与张量Tensor的介绍"><a href="#Pytorch的使用与张量Tensor的介绍" class="headerlink" title="Pytorch的使用与张量Tensor的介绍"></a>Pytorch的使用与张量Tensor的介绍</h3><h5 id="randint"><a href="#randint" class="headerlink" title="randint"></a>randint</h5><p>训练模型过程中，我们需要用到<strong>随机的整数</strong>，在torch库中和random库使用相似比如说</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成-100，100的随机整数</span></span><br><span class="line">randint=torch.randint(-<span class="number">100</span>,<span class="number">100</span>,(<span class="number">6</span>,))</span><br></pre></td></tr></table></figure>

<p>输出结果为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[OUT]:tensor([-<span class="number">85</span>][<span class="number">11</span>][<span class="number">54</span>][<span class="number">53</span>][-<span class="number">98</span>][<span class="number">9</span>])</span><br></pre></td></tr></table></figure>

<p>这个函数实际参数使用为：</p>
<p>​						【一些函数含有默认值】</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randint(low=<span class="number">0</span>, high, size, *, generator=<span class="literal">None</span>, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, layout=torch.strided, device=<span class="literal">None</span>, requires_grad=<span class="literal">False</span>, pin_memory=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>参数说明</p>
<table>
<thead>
<tr>
<th align="center">参数名</th>
<th>介绍</th>
<th align="center">使用</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong><code>low</code></strong></td>
<td>整数类型。生成随机整数的下边界（包含在内）。 默认值为 0</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>high</code></strong></td>
<td>整数类型。生成随机整数的上边界（不包含在内）</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><strong><code>size</code></strong></td>
<td>整数或整数元组。指定输出张量的形状。例如，<code>(2, 3)</code> 表示生成一个 2x3 的张量</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><strong><code>generator</code></strong></td>
<td><code>torch.Generator</code> 对象。用于指定用于生成随机数的生成器。</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>out</code></strong></td>
<td><code>torch.Tensor</code>。指定输出的张量。如果提供，则将结果填充到该张量中。</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>dtype</code></strong></td>
<td>数据类型。指定输出张量的数据类型，默认是 <code>torch.int64</code>。</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>layout</code></strong></td>
<td><code>torch.layout</code>。指定输出张量的布局，默认是 <code>torch.strided</code>。</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>device</code></strong></td>
<td><code>torch.device</code>。指定输出张量所在的设备 <code>torch.device(&#39;cpu&#39;)</code> 或 <code>torch.device(&#39;cuda&#39;)</code></td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>requires_grad</code></strong></td>
<td>布尔类型。如果为 <code>True</code>，则允许对输出张量进行梯度计算。</td>
<td align="center">（可选）</td>
</tr>
<tr>
<td align="center"><strong><code>pin_memory</code></strong></td>
<td>布尔类型。如果为 <code>True</code>，则在锁页内存中分配输出张量。</td>
<td align="center">（可选）</td>
</tr>
</tbody></table>
<h5 id="tensor"><a href="#tensor" class="headerlink" title="tensor"></a>tensor</h5><p>如果我们需要建立一个我们自己定义的张量则为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.tensor([<span class="number">0.1</span>,<span class="number">1.2</span>],[<span class="number">2.2</span>,<span class="number">3.1</span>],[<span class="number">4.9</span>,<span class="number">5.2</span>])</span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[OUT]:tensor([[<span class="number">0.1000</span>,<span class="number">1.2000</span>],</span><br><span class="line">              [<span class="number">2.2000</span>,<span class="number">3.1000</span>],</span><br><span class="line">              [<span class="number">4.9000</span>,<span class="number">5.2000</span>]])</span><br></pre></td></tr></table></figure>

<p>如上，我们得到了个3*2的矩阵，因为我们自定义值为浮点值，所以输出的张量也会以浮点形式存在</p>
<h5 id="zeros"><a href="#zeros" class="headerlink" title="zeros"></a>zeros</h5><p>如果我们需要建立一个zeros的张量则为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zeros = torch.zeros(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(zeros)</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[OUT]:tensor([[<span class="number">0.</span>,<span class="number">0.</span>,<span class="number">0.</span>,],</span><br><span class="line">              [<span class="number">0.</span>,<span class="number">0.</span>,<span class="number">0.</span>,]])</span><br></pre></td></tr></table></figure>

<p>如上，我们得到了个2*3的零矩阵，注意这些值也是浮点值</p>
<h5 id="ones"><a href="#ones" class="headerlink" title="ones"></a>ones</h5><p>如果我们需要建立一个ones的张量则为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ones = torch.ones(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(ones)</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[OUT]:tensor([[<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,],</span><br><span class="line">              [<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,]</span><br><span class="line">              [<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>,]])</span><br></pre></td></tr></table></figure>

<p>如上，我们得到了个3*4的一矩阵，注意这些值也是浮点值</p>
<h5 id="empty"><a href="#empty" class="headerlink" title="empty"></a>empty</h5><p>如果我们需要建立一个空的张量则为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">empty = torch.empty(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(empty)</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.creamcrepe.icu">奶油可丽饼🍭</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.creamcrepe.icu/2024/07/20/pytorch-LLM/">https://blog.creamcrepe.icu/2024/07/20/pytorch-LLM/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.creamcrepe.icu" target="_blank">奶油可丽饼🍭</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/pytorch/">pytorch</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/06/27/aYAs14kdBTVrGhQ.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/07/21/pytorch-learn1/" title="pytorch加载数据集认识"><img class="cover" src="https://s2.loli.net/2024/06/27/PA6cJsgNnvCM2hp.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">pytorch加载数据集认识</div></div></a></div><div class="next-post pull-right"><a href="/2024/07/16/pytorch-neuron/" title="神经网络工程学"><img class="cover" src="https://s2.loli.net/2024/06/27/uPYc12rWIEAOwFo.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">神经网络工程学</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/07/04/pytorch-anaconda/" title="anaconda配置与基础指令"><img class="cover" src="https://s2.loli.net/2024/06/27/fmDXNEvLjBu7ngq.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-04</div><div class="title">anaconda配置与基础指令</div></div></a></div><div><a href="/2024/07/16/pytorch-neuron/" title="神经网络工程学"><img class="cover" src="https://s2.loli.net/2024/06/27/uPYc12rWIEAOwFo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-16</div><div class="title">神经网络工程学</div></div></a></div><div><a href="/2024/06/26/pytorch-setting/" title="pytoch环境下载与安装"><img class="cover" src="https://s2.loli.net/2024/06/27/fmDXNEvLjBu7ngq.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-26</div><div class="title">pytoch环境下载与安装</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2024/06/26/zjr3sIaPb9TQJC8.jpg" onerror="this.onerror=null;this.src='https://s2.loli.net/2024/06/27/ogFMRzISiKtZVal.gif'" alt="avatar"/></div><div class="author-info__name">奶油可丽饼🍭</div><div class="author-info__description">病名唯爱</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/TadanoAI"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://space.bilibili.com/13763517?spm_id_from=333.1007.0.0" target="_blank" title="Bilibili"><i class="fab fa-bilibili" style="color: #ff8aad;"></i></a><a class="social-icon" href="https://github.com/TadanoAI" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://x.com/CrepeA1" target="_blank" title="twitter"><i class="fab fa-x-twitter" style="color: ;"></i></a><a class="social-icon" href="https://qm.qq.com/q/y8jsnBRbaw" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #74C0FC;"></i></a><a class="social-icon" href="https://steamcommunity.com/id/griffithprprpr/" target="_blank" title="Steam"><i class="fa-brands fa-steam" style="color: ;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">目标是征服星辰大海!🚀</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">前言：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#bilibili%E6%90%AC%E8%BF%90"><span class="toc-number">1.1.</span> <span class="toc-text">bilibili搬运:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#youtube"><span class="toc-number">1.2.</span> <span class="toc-text">youtube:</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">简介：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87%E4%B8%BA%E4%BA%8C%E5%85%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.0.0.0.1.</span> <span class="toc-text">训练目标为二元语言模型</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">安装环境：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83"><span class="toc-number">3.0.1.</span> <span class="toc-text">配置环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Jupyter-Notebook"><span class="toc-number">3.0.2.</span> <span class="toc-text">Jupyter Notebook</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.0.3.</span> <span class="toc-text">获取数据集</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">训练：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E5%AD%97%E5%85%B8%E5%AF%B9%E5%AD%97%E7%AC%A6%E8%BF%9B%E8%A1%8C%E7%BC%96%E7%A0%81"><span class="toc-number">4.0.1.</span> <span class="toc-text">建立字典对字符进行编码</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A7%84%E5%88%99%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.0.1.0.1.</span> <span class="toc-text">规则模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8tourch%E5%BA%93"><span class="toc-number">4.0.2.</span> <span class="toc-text">使用tourch库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%92%8C%E8%AE%AD%E7%BB%83%E6%8B%86%E5%88%86"><span class="toc-number">4.0.3.</span> <span class="toc-text">验证和训练拆分</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8B%86%E5%88%86"><span class="toc-number">4.0.3.0.1.</span> <span class="toc-text">拆分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%8E%9F%E7%90%86"><span class="toc-number">4.0.3.0.2.</span> <span class="toc-text">训练原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A7%84%E6%95%B4%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.0.3.0.3.</span> <span class="toc-text">规整模型</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%EF%BC%9A"><span class="toc-number">5.</span> <span class="toc-text">使用说明：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pytorch%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%BC%A0%E9%87%8FTensor%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.0.1.</span> <span class="toc-text">Pytorch的使用与张量Tensor的介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#randint"><span class="toc-number">5.0.1.0.1.</span> <span class="toc-text">randint</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tensor"><span class="toc-number">5.0.1.0.2.</span> <span class="toc-text">tensor</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#zeros"><span class="toc-number">5.0.1.0.3.</span> <span class="toc-text">zeros</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ones"><span class="toc-number">5.0.1.0.4.</span> <span class="toc-text">ones</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#empty"><span class="toc-number">5.0.1.0.5.</span> <span class="toc-text">empty</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/26/hello-world/" title="如何创建新帖子"><img src="https://s2.loli.net/2024/06/27/sM82Ee3QY6mSxAn.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何创建新帖子"/></a><div class="content"><a class="title" href="/2024/07/26/hello-world/" title="如何创建新帖子">如何创建新帖子</a><time datetime="2024-07-26T02:12:09.076Z" title="发表于 2024-07-26 10:12:09">2024-07-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/21/pytorch-learn1/" title="pytorch加载数据集认识"><img src="https://s2.loli.net/2024/06/27/PA6cJsgNnvCM2hp.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pytorch加载数据集认识"/></a><div class="content"><a class="title" href="/2024/07/21/pytorch-learn1/" title="pytorch加载数据集认识">pytorch加载数据集认识</a><time datetime="2024-07-20T16:04:41.000Z" title="发表于 2024-07-21 00:04:41">2024-07-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/20/pytorch-LLM/" title="学习从零开始用Python搭建LLM"><img src="https://s2.loli.net/2024/06/27/aYAs14kdBTVrGhQ.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="学习从零开始用Python搭建LLM"/></a><div class="content"><a class="title" href="/2024/07/20/pytorch-LLM/" title="学习从零开始用Python搭建LLM">学习从零开始用Python搭建LLM</a><time datetime="2024-07-20T15:52:36.000Z" title="发表于 2024-07-20 23:52:36">2024-07-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/16/pytorch-neuron/" title="神经网络工程学"><img src="https://s2.loli.net/2024/06/27/uPYc12rWIEAOwFo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络工程学"/></a><div class="content"><a class="title" href="/2024/07/16/pytorch-neuron/" title="神经网络工程学">神经网络工程学</a><time datetime="2024-07-15T16:14:12.000Z" title="发表于 2024-07-16 00:14:12">2024-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/15/math-markdown-math-formula/" title="MarkDown数学公式语法"><img src="https://s2.loli.net/2024/06/27/I96iODM7dLyW4P8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MarkDown数学公式语法"/></a><div class="content"><a class="title" href="/2024/07/15/math-markdown-math-formula/" title="MarkDown数学公式语法">MarkDown数学公式语法</a><time datetime="2024-07-15T09:14:20.000Z" title="发表于 2024-07-15 17:14:20">2024-07-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By 奶油可丽饼🍭</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"></div><script async src="/js/title.js"></script><script defer="defer" id="fluttering_ribbon" mobile="ture" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/Blender/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐒 Blender (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/IIOT/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🌏 物联网 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/pytorch/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🤖 机器学习 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🔢 数学与工程学 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/learn/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📒 学习 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://blog.creamcrepe.icu/tags/自主项目/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 自主项目 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://blog.creamcrepe.icu/tags" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '700ms');
    arr[i].setAttribute('data-wow-delay', '700ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":"ture"},"log":false});</script></body></html>